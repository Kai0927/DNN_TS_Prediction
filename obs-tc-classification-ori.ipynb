{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"id":"st6r5TecqE6J","outputId":"8330c8e2-1b15-4674-c9cb-de5624333450","execution":{"iopub.status.busy":"2023-08-30T07:49:19.087940Z","iopub.execute_input":"2023-08-30T07:49:19.088398Z","iopub.status.idle":"2023-08-30T07:49:19.096069Z","shell.execute_reply.started":"2023-08-30T07:49:19.088362Z","shell.execute_reply":"2023-08-30T07:49:19.095059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"bOMmOG2_qwcM","outputId":"b9d6e4dd-174d-42a0-a0ba-8d2b8f6b8986","execution":{"iopub.status.busy":"2023-08-30T07:49:19.106875Z","iopub.execute_input":"2023-08-30T07:49:19.107189Z","iopub.status.idle":"2023-08-30T07:49:20.296419Z","shell.execute_reply.started":"2023-08-30T07:49:19.107162Z","shell.execute_reply":"2023-08-30T07:49:20.295295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.299822Z","iopub.execute_input":"2023-08-30T07:49:20.300147Z","iopub.status.idle":"2023-08-30T07:49:20.306784Z","shell.execute_reply.started":"2023-08-30T07:49:20.300116Z","shell.execute_reply":"2023-08-30T07:49:20.305703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/obs-data/New_OBS_DATA_FOR_ML.csv')\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.308413Z","iopub.execute_input":"2023-08-30T07:49:20.309027Z","iopub.status.idle":"2023-08-30T07:49:20.475509Z","shell.execute_reply.started":"2023-08-30T07:49:20.308995Z","shell.execute_reply":"2023-08-30T07:49:20.474497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(df.columns)\nfeatures.remove('TC_or_NTC')\n\nprint('特徵數: ', len(features))\nfeatures","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.478110Z","iopub.execute_input":"2023-08-30T07:49:20.478544Z","iopub.status.idle":"2023-08-30T07:49:20.487706Z","shell.execute_reply.started":"2023-08-30T07:49:20.478510Z","shell.execute_reply":"2023-08-30T07:49:20.486805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('數值型特徵數: ', df[features].describe().shape[1]-1)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.489063Z","iopub.execute_input":"2023-08-30T07:49:20.490176Z","iopub.status.idle":"2023-08-30T07:49:20.748012Z","shell.execute_reply.started":"2023-08-30T07:49:20.490086Z","shell.execute_reply":"2023-08-30T07:49:20.746973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 相關係數矩陣\ncor_matrix = df.corr(numeric_only=True)\ncor_matrix","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.749458Z","iopub.execute_input":"2023-08-30T07:49:20.749880Z","iopub.status.idle":"2023-08-30T07:49:20.891242Z","shell.execute_reply.started":"2023-08-30T07:49:20.749848Z","shell.execute_reply":"2023-08-30T07:49:20.890256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# HeatMap of Correlation Matrix\nplt.figure(figsize=(40,40))\nmask = np.triu(np.ones_like(cor_matrix, dtype=bool))\nsns.heatmap(cor_matrix, annot=True, mask=mask, vmin=-1, vmax=1)\nplt.title('Correlation Coefficient of Predictors')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:20.892784Z","iopub.execute_input":"2023-08-30T07:49:20.893146Z","iopub.status.idle":"2023-08-30T07:49:24.622258Z","shell.execute_reply.started":"2023-08-30T07:49:20.893116Z","shell.execute_reply":"2023-08-30T07:49:24.620868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 篩選相關係數大於 0.8 的特徵\nthresh = 0.8\nmask = abs(cor_matrix) > thresh\ncor_matrix.where(mask).stack()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:24.623760Z","iopub.execute_input":"2023-08-30T07:49:24.624422Z","iopub.status.idle":"2023-08-30T07:49:24.637571Z","shell.execute_reply.started":"2023-08-30T07:49:24.624387Z","shell.execute_reply":"2023-08-30T07:49:24.636848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_vif(considered_features):\n\n    X = df.loc[:,considered_features]\n    X = X.dropna()\n    X['intercept'] = 1\n\n    vif = pd.DataFrame()\n    vif[\"Variable\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif = vif.loc[vif['Variable']!='intercept']\n\n    return vif","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:24.638957Z","iopub.execute_input":"2023-08-30T07:49:24.639585Z","iopub.status.idle":"2023-08-30T07:49:24.645857Z","shell.execute_reply.started":"2023-08-30T07:49:24.639553Z","shell.execute_reply":"2023-08-30T07:49:24.644971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 考慮要刪除的特徵\nconsidered_features = ['dtd8', 'dtd9', 'dtd10', 'dtd11', 'dtd12', 'dtd13', \n           'rh8', 'rh9', 'rh10', 'rh11', 'rh12', 'rh13', \n           'M8', 'M9', 'M10', 'M11', 'M12', 'M13']\n\n# 計算 VIF\ncompute_vif(considered_features).sort_values('VIF', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:24.650590Z","iopub.execute_input":"2023-08-30T07:49:24.651349Z","iopub.status.idle":"2023-08-30T07:49:24.987700Z","shell.execute_reply.started":"2023-08-30T07:49:24.651317Z","shell.execute_reply":"2023-08-30T07:49:24.986806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 刪除 'Horsepower' 與 Power_perf_factor' 後計算 VIF\nconsidered_features = ['dtd8', 'dtd9', 'dtd10', 'dtd11', 'dtd12', 'dtd13', \n           'rh8', 'rh9', 'rh10', 'rh11', 'rh12', 'rh13', \n           'M8', 'M9', 'M10', 'M11', 'M12', 'M13']\n\nfor f in ['dtd8', 'dtd9', 'dtd10', 'dtd11', 'dtd12', 'dtd13', \n           'rh8', 'rh9', 'rh10', 'rh11', 'rh12', 'rh13', 'M9', 'M10', 'M11']:\n    considered_features.remove(f)\n\ncompute_vif(considered_features).sort_values('VIF', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:24.989342Z","iopub.execute_input":"2023-08-30T07:49:24.990030Z","iopub.status.idle":"2023-08-30T07:49:25.030232Z","shell.execute_reply.started":"2023-08-30T07:49:24.989996Z","shell.execute_reply":"2023-08-30T07:49:25.029170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical Operations\nimport math\nimport numpy as np\n\n# Reading/Writing Data\nimport pandas as pd\nimport os\nimport csv\n\n# For Progress Bar\nfrom tqdm import tqdm\n\n# Pytorch\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\n# For plotting learning curve\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom sklearn.model_selection import KFold\nkfold = KFold(n_splits=4, shuffle=True)","metadata":{"id":"4o2M99Dfrs5X","execution":{"iopub.status.busy":"2023-08-30T07:49:25.031946Z","iopub.execute_input":"2023-08-30T07:49:25.032602Z","iopub.status.idle":"2023-08-30T07:49:25.039866Z","shell.execute_reply.started":"2023-08-30T07:49:25.032569Z","shell.execute_reply":"2023-08-30T07:49:25.038759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def same_seed(seed): \n    '''Fixes random number generator seeds for reproducibility.'''\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\ndef train_valid_split(data_set, valid_ratio, seed):\n    '''Split provided training data into training set and validation set'''\n    valid_set_size = int(valid_ratio * len(data_set)) \n    train_set_size = len(data_set) - valid_set_size\n    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n    return np.array(train_set), np.array(valid_set)\ndef predict(test_loader, model, device):\n    model.eval() # Set your model to evaluation mode.\n    preds = []\n    for x in tqdm(test_loader):\n        x = x.to(device)                        \n        with torch.no_grad():                   \n            pred = model(x)                     \n            preds.append(pred.detach().cpu())   \n    preds = torch.cat(preds, dim=0).numpy()  \n    return preds","metadata":{"id":"rlSv68MUspnd","execution":{"iopub.status.busy":"2023-08-30T07:49:25.041675Z","iopub.execute_input":"2023-08-30T07:49:25.042397Z","iopub.status.idle":"2023-08-30T07:49:25.057091Z","shell.execute_reply.started":"2023-08-30T07:49:25.042364Z","shell.execute_reply":"2023-08-30T07:49:25.055843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OBSDataset(Dataset):\n    '''\n    x: Features.\n    y: Targets, if none, do prediction.\n    '''\n    def __init__(self, x, y=None):\n        if y is None:\n            self.y = y\n        else: \n            self.y = torch.FloatTensor(y)\n        self.x = torch.FloatTensor(x)\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.x[idx]\n        else:\n            return self.x[idx], self.y[idx]\n\n    def __len__(self):\n        return len(self.x)","metadata":{"id":"1owtXI50s8Yd","execution":{"iopub.status.busy":"2023-08-30T07:49:25.058999Z","iopub.execute_input":"2023-08-30T07:49:25.059695Z","iopub.status.idle":"2023-08-30T07:49:25.070510Z","shell.execute_reply.started":"2023-08-30T07:49:25.059662Z","shell.execute_reply":"2023-08-30T07:49:25.069265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class My_Model(nn.Module):\n    def __init__(self, input_dim):\n        super(My_Model, self).__init__()\n        # TODO: modify model's structure, be aware of dimensions.\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 31),\n            nn.BatchNorm1d(31),\n            nn.LeakyReLU(),\n            nn.Linear(31, 16),\n            nn.BatchNorm1d(16),\n            nn.LeakyReLU(),\n            nn.Linear(16, 8),\n            nn.BatchNorm1d(8),\n            nn.LeakyReLU(),            \n            nn.Linear(8, 1)\n        )\n\n    def forward(self, x):\n        x = self.layers(x)\n        #x = x.squeeze(1) # (B, 1) -> (B)\n        return x","metadata":{"id":"RtSh-90CtCWd","execution":{"iopub.status.busy":"2023-08-30T07:49:25.072331Z","iopub.execute_input":"2023-08-30T07:49:25.073031Z","iopub.status.idle":"2023-08-30T07:49:25.082823Z","shell.execute_reply.started":"2023-08-30T07:49:25.072999Z","shell.execute_reply":"2023-08-30T07:49:25.081596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_feat(train_data, valid_data, test_data, select_all=True):\n    '''Selects useful features to perform regression'''\n    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n\n    if select_all:\n        feat_idx = list(range(raw_x_train.shape[1]))\n    else:\n        feat_idx = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,27,31,32,33,34,35,36,37,38,39,40,41,42,43,44] # TODO: Select suitable feature columns.\n        len_feat_idx = len(feat_idx)\n    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid, len_feat_idx","metadata":{"id":"SEOXDUhItDoU","execution":{"iopub.status.busy":"2023-08-30T07:49:25.084827Z","iopub.execute_input":"2023-08-30T07:49:25.085504Z","iopub.status.idle":"2023-08-30T07:49:25.098052Z","shell.execute_reply.started":"2023-08-30T07:49:25.085472Z","shell.execute_reply":"2023-08-30T07:49:25.096756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainer(train_loader, valid_loader, model, config, device):\n    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n    #criterion = nn.L1Loss() \n    \n    # Define your optimization algorithm. \n    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n    warmup_steps = 50\n    #optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9) \n    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n    #scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, config['n_epochs'])                              \n    writer = SummaryWriter() # Writer of tensoboard.\n\n    if not os.path.isdir('./models'):\n        os.mkdir('./models') # Create directory of saving models.\n\n    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n    loss_train=[]; loss_val=[]\n    for epoch in range(n_epochs):\n        model.train() # Set your model to train mode.\n        loss_record = []\n\n        # tqdm is a package to visualize your training progress.\n        train_pbar = tqdm(train_loader, position=0, leave=True)\n        for x, y in train_loader:\n            for x, y in train_pbar:\n                optimizer.zero_grad()               # Set gradient to zero.\n                y = torch.reshape(y,(len(y),1))\n                x, y = x.to(device), y.to(device)   # Move your data to device.\n                pred = model(x)             \n                loss = criterion(pred, y)\n                loss.backward()                     # Compute gradient(backpropagation).\n                optimizer.step()                    # Update parameters.\n                #scheduler.step()\n                step += 1\n                loss_record.append(loss.detach().item())\n\n                # Display current epoch number and loss on tqdm progress bar.\n                train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n                train_pbar.set_postfix({'loss': loss.detach().item()})\n\n        mean_train_loss = sum(loss_record)/len(loss_record)\n        writer.add_scalar('Loss/train', mean_train_loss, step)\n\n        model.eval() # Set your model to evaluation mode.\n        loss_record = []\n        for x, y in valid_loader:\n            y = torch.reshape(y,(len(y),1))\n            x, y = x.to(device), y.to(device)\n            with torch.no_grad():\n                pred = model(x)\n                loss = criterion(pred, y)\n\n            loss_record.append(loss.item())\n            \n        mean_valid_loss = sum(loss_record)/len(loss_record)\n        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n        loss_train.append(mean_train_loss);loss_val.append(mean_valid_loss);\n        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n\n        if mean_valid_loss < best_loss :#and mean_valid_loss<0.123:\n            best_loss = mean_valid_loss\n            torch.save(model.state_dict(), config['save_path']) # Save your best model\n            print('Saving model with loss {:.3f}...'.format(best_loss))\n            early_stop_count = 0\n        else: \n            early_stop_count += 1\n\n        if early_stop_count >= config['early_stop']:\n            print('\\nModel is not improving, so we halt the training session.')\n            return loss_train, loss_val","metadata":{"id":"zJFlqVgQ887S","execution":{"iopub.status.busy":"2023-08-30T07:49:25.100040Z","iopub.execute_input":"2023-08-30T07:49:25.100717Z","iopub.status.idle":"2023-08-30T07:49:25.128222Z","shell.execute_reply.started":"2023-08-30T07:49:25.100685Z","shell.execute_reply":"2023-08-30T07:49:25.126836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n    if hasattr(layer, 'reset_parameters'):\n        print(f'Reset trainable parameters of layer = {layer}')\n        layer.reset_parameters()","metadata":{"id":"h7KVzua4e483","execution":{"iopub.status.busy":"2023-08-30T07:49:25.130209Z","iopub.execute_input":"2023-08-30T07:49:25.130945Z","iopub.status.idle":"2023-08-30T07:49:25.137655Z","shell.execute_reply.started":"2023-08-30T07:49:25.130914Z","shell.execute_reply":"2023-08-30T07:49:25.136444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nconfig = {\n    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n    'select_all': False,   # Whether to use all features.\n    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n    'n_epochs': 100,     # Number of epochs.            \n    'batch_size': 128, \n    'learning_rate': 1e-5,              \n    'early_stop': 50,    # If model has not improved for this many consecutive epochs, stop training.     \n    'save_path': './models/model.ckpt'  # Your model will be saved here.\n}","metadata":{"id":"1Zc6wppftOQE","execution":{"iopub.status.busy":"2023-08-30T07:49:25.139614Z","iopub.execute_input":"2023-08-30T07:49:25.140304Z","iopub.status.idle":"2023-08-30T07:49:25.147218Z","shell.execute_reply.started":"2023-08-30T07:49:25.140271Z","shell.execute_reply":"2023-08-30T07:49:25.145998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\n\n\ndef collate_batch(batch):\n    # Process features within a batch.\n    \"\"\"Collate a batch of data.\"\"\"\n    x, y = zip(*batch)\n    #print(x)\n    # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n    x = pad_sequence(x, batch_first=True)#, padding_value=-20)    # pad log 10^(-20) which is very small value.\n    #print(x.shape)\n    # mel: (batch size, length, 40)\n    return x, torch.FloatTensor(y)#.long()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T07:49:25.149159Z","iopub.execute_input":"2023-08-30T07:49:25.149907Z","iopub.status.idle":"2023-08-30T07:49:25.158845Z","shell.execute_reply.started":"2023-08-30T07:49:25.149836Z","shell.execute_reply":"2023-08-30T07:49:25.157903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set seed for reproducibility\nsame_seed(config['seed'])\n\ntrain_data, test_data = pd.read_csv('../input/obs-data/New_OBS_DATA_FOR_ML.csv').values, pd.read_csv('../input/obs-data/New_test_OBS_DATA_FOR_ML.csv').values\n\n# K-fold Cross Validation model evaluation\n#for fold, (train_ids, test_ids) in enumerate(kfold.split(train_data)):\n#    print(f'FOLD {fold}')\n#    print('--------------------------------') \n#train_data_f = torch.tensor([train_data[i] for i in train_ids],dtype=torch.float32)\n#valid_data_f = torch.tensor([train_data[j] for j in test_ids],dtype=torch.float32)\n#test_data = torch.tensor(test_data,dtype=torch.float32)\n\ntrain_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n\n# Print out the data size.\nprint(f\"\"\"train_data size: {train_data.shape} \nvalid_data size: {valid_data.shape} \ntest_data size: {test_data.shape}\"\"\")\n\n# Select features\nx_train, x_valid, x_test, y_train, y_valid, len_feat_idx = select_feat(train_data, valid_data, test_data, config['select_all'])\n\n# Print out the number of features.\nprint(f'number of features: {x_train.shape[1]}')\n\ntrain_dataset, valid_dataset, test_dataset = OBSDataset(x_train, y_train), \\\n                        OBSDataset(x_valid, y_valid), \\\n                        OBSDataset(x_test)\n\n# Pytorch data loader loads pytorch dataset into batches.\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)#,drop_last=True,collate_fn=collate_batch)\nvalid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)#,drop_last=True,collate_fn=collate_batch)\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)#,drop_last=True,collate_fn=collate_batch)\n\nmodel = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n#model.apply(reset_weights)\na, b = trainer(train_loader, valid_loader, model, config, device)","metadata":{"id":"wvT3yi0NtTFl","outputId":"9c318b7a-fdeb-4ce6-8ed6-a7e3294dde7d","execution":{"iopub.status.busy":"2023-08-30T07:49:25.160420Z","iopub.execute_input":"2023-08-30T07:49:25.161076Z","iopub.status.idle":"2023-08-30T09:09:02.843176Z","shell.execute_reply.started":"2023-08-30T07:49:25.161044Z","shell.execute_reply":"2023-08-30T09:09:02.841024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install shap==0.39.0\n#!conda list -n shap\n#!pip install shapely==1.7.1","metadata":{"execution":{"iopub.status.busy":"2023-08-30T09:09:02.844669Z","iopub.execute_input":"2023-08-30T09:09:02.845481Z","iopub.status.idle":"2023-08-30T09:09:02.850117Z","shell.execute_reply.started":"2023-08-30T09:09:02.845444Z","shell.execute_reply":"2023-08-30T09:09:02.849146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport shap\nimport numpy as np\n\nsaved_model_path = config['save_path']\ncheckpoint = torch.load(saved_model_path)\n\n# Step 4: Load the parameters into the model\nmodel.load_state_dict(checkpoint)\nprint(model)\n\nbatch = next(iter(test_loader))\nprint(batch)\nx = batch#[0:100]\nx = x.to(device)\nprint(x.shape, type(model), type(x))\n#x = torch.reshape(x,(1,178,31))\n#print(x.shape)\n#x = torch.permute(x, (2, 1, 0))\n#print(x.shape)\ne = shap.DeepExplainer(model, x)  \n\n# Get the shap values from my test data (this explainer likes tensors)\nshap_values = e.shap_values(x) \n\n# Plots\n#shap.force_plot(explainer.expected_value, shap_values, feature_names)\n#shap.dependence_plot(\"b1_price_avg\", shap_values, data, feature_names)\nfeature_names = [ 'lat', 'lon', 'alt', \n           'p9', 'p10', 'p11', 'p12',\n           't9', 't10', 't11', 't12', \n           'dtd9', 'dtd10', 'dtd11', 'dtd12', \n           'rh9', 'rh10', 'rh11', 'rh12', \n           'M9', 'M10', 'M11', 'M12', \n           'wd9', 'wd10', 'wd11', 'wd12',  \n           'ws9', 'ws10', 'ws11', 'ws12'\n         ]\nshap.summary_plot(shap_values, x, plot_type='bar',feature_names=feature_names)","metadata":{"id":"40udDd3cEOfz","execution":{"iopub.status.busy":"2023-08-30T09:09:02.851417Z","iopub.execute_input":"2023-08-30T09:09:02.852378Z","iopub.status.idle":"2023-08-30T09:09:05.460097Z","shell.execute_reply.started":"2023-08-30T09:09:02.852346Z","shell.execute_reply":"2023-08-30T09:09:05.459200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\na = np.asarray(a)\nprint(a.shape)\nlen_epoch = np.linspace(0,len(a),len(a))\nplt.plot(len_epoch,a)\nplt.plot(len_epoch,b)\nplt.legend(['train_loss','valid_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T09:09:05.461482Z","iopub.execute_input":"2023-08-30T09:09:05.461944Z","iopub.status.idle":"2023-08-30T09:09:05.727466Z","shell.execute_reply.started":"2023-08-30T09:09:05.461908Z","shell.execute_reply":"2023-08-30T09:09:05.725354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_pred(preds, file):\n    ''' Save predictions to specified file '''\n    with open(file, 'w') as fp:\n        writer = csv.writer(fp)\n        writer.writerow(['id', 'TC/NTC (1/0)'])\n        for i, p in enumerate(preds):\n            if (p>=0.5):\n              p = 1\n            else:\n              p=0\n            writer.writerow([i, p])\n#test_data = torch.tensor(test_data,dtype=torch.float32)\n#x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data_f, valid_data_f, test_data, config['select_all'])\n#test_dataset = OBSDataset(x_test)\n#test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\nmodel = My_Model(input_dim=x_train.shape[1]).to(device)\nmodel.load_state_dict(torch.load(config['save_path']))\npreds = predict(test_loader, model, device) \nsave_pred(preds, 'pred.csv')      ","metadata":{"id":"xZ8vNR-F-EOj","execution":{"iopub.status.busy":"2023-08-30T09:09:05.728948Z","iopub.execute_input":"2023-08-30T09:09:05.729944Z","iopub.status.idle":"2023-08-30T09:09:05.924361Z","shell.execute_reply.started":"2023-08-30T09:09:05.729908Z","shell.execute_reply":"2023-08-30T09:09:05.923352Z"},"trusted":true},"execution_count":null,"outputs":[]}]}